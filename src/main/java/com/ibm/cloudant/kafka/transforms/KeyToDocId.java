/*
 * Copyright Â© 2022 IBM Corp. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file
 * except in compliance with the License. You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software distributed under the
 * License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,
 * either express or implied. See the License for the specific language governing permissions
 * and limitations under the License.
 */
package com.ibm.cloudant.kafka.transforms;

import org.apache.kafka.common.cache.Cache;
import org.apache.kafka.common.cache.LRUCache;
import org.apache.kafka.common.cache.SynchronizedCache;
import org.apache.kafka.common.config.ConfigDef;
import org.apache.kafka.connect.connector.ConnectRecord;
import org.apache.kafka.connect.data.Field;
import org.apache.kafka.connect.data.Schema;
import org.apache.kafka.connect.data.SchemaBuilder;
import org.apache.kafka.connect.data.Struct;
import org.apache.kafka.connect.transforms.Transformation;
import org.apache.kafka.connect.transforms.util.SchemaUtil;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.HashMap;
import java.util.Map;
import java.util.Optional;

import static org.apache.kafka.connect.transforms.util.Requirements.requireMapOrNull;
import static org.apache.kafka.connect.transforms.util.Requirements.requireSinkRecord;
import static org.apache.kafka.connect.transforms.util.Requirements.requireStructOrNull;

public class KeyToDocId<R extends ConnectRecord<R>> implements Transformation<R> {

    public static final String OVERVIEW_DOC = "Extract the record's key and save the value to the '_id' field. " +
            "If the '_id' field already exists, the value will be overwritten." +
            "If the record key is absent, null or empty, the record will be unmodified and an _id will be generated by Cloudant.";

    public static final ConfigDef CONFIG_DEF = new ConfigDef();

    private static final String PURPOSE = "Copy record key to _id value";

    private static final String idFieldName = "_id";

    private Cache<Schema, Schema> schemaUpdateCache = new SynchronizedCache<>(new LRUCache<Schema, Schema>(16));

    private static Logger LOG = LoggerFactory.getLogger(KeyToDocId.class.toString());

    public void configure(Map<String, ?> configs) {
        // no config required
    }

    public R apply(R record) {
        if (requireSinkRecord(record, PURPOSE).key() != null
                && record.key() instanceof String) {
            if (record.valueSchema() == null) {
                return applySchemaless(record);
            } else {
                return applyWithSchema(record);
            }
        } else {
            LOG.info("The message was left unmodified. Please check that this transform is being used during sink "
                    + "process and the record key is of type string.");
            return record;
        }
    }

    private R applySchemaless(R record) {
        final Map<String, Object> value;
        if (record.value() == null) {
            value = new HashMap<>(1);
        } else {
            value = requireMapOrNull(record.value(), PURPOSE);
        }
        final Map<String, Object> updatedValue = new HashMap<>(value);
        addKeyToValueIdField(record, updatedValue);

        return record.newRecord(
                record.topic(),
                record.kafkaPartition(),
                record.keySchema(),
                record.key(),
                record.valueSchema(),
                updatedValue,
                record.timestamp()
        );
    }

    private R applyWithSchema(R record) {
        if (record.value() == null || record.value() instanceof Map) {
            return updateValueUsingMapSchema(record);
        } else if (record.value() instanceof Struct) {
            return updateValueUsingStructSchema(record);
        } else {
            LOG.info("Unsupported record type. Leaving record unmodified.");
            return record;
        }
    }

    private R updateValueUsingStructSchema(R record) {
        Struct recordValue = requireStructOrNull(record.value(), PURPOSE);
        Schema updatedSchema = schemaUpdateCache.get(recordValue.schema());
        Struct updatedValue;
        // only update the value schema if _id field doesn't exist
        if (updatedSchema == null && recordValue.schema().field(idFieldName) == null) {
            updatedSchema = makeUpdatedSchema(recordValue.schema());
            schemaUpdateCache.put(recordValue.schema(), updatedSchema);
            updatedValue = new Struct(updatedSchema);
        } else {
            schemaUpdateCache.put(recordValue.schema(), recordValue.schema());
            updatedValue = new Struct(recordValue.schema());
        }

        addKeyToValueIdField(record, updatedValue);

        // add field names and values from original to updated struct
        for (Field field : recordValue.schema().fields()) {
            updatedValue.put(field.name(), recordValue.get(field));
        }
        return record.newRecord(
                record.topic(),
                record.kafkaPartition(),
                record.keySchema(),
                record.key(),
                Optional.ofNullable(updatedSchema).orElse(record.valueSchema()),
                updatedValue,
                record.timestamp()
        );
    }

    private R updateValueUsingMapSchema(R record) {
        Map updatedValue = requireMapOrNull(record.value(), PURPOSE);
        if (updatedValue != null) {
            addKeyToValueIdField(record, updatedValue);
        } else {
            updatedValue = new HashMap<>(1);
            addKeyToValueIdField(record, updatedValue);
        }
        return record.newRecord(
                record.topic(),
                record.kafkaPartition(),
                record.keySchema(),
                record.key(),
                record.valueSchema(),
                updatedValue,
                record.timestamp()
        );
    }

    private void addKeyToValueIdField(R record, Object updatedValue) {
        if (updatedValue instanceof Struct) {
            ((Struct) updatedValue).put(idFieldName, record.key());
        } else if (updatedValue instanceof Map) {
            ((Map) updatedValue).put(idFieldName, record.key());
        } else {
            LOG.info("The updated value object is unsupported. Leaving message value unmodified.");
        }
    }

    private Schema makeUpdatedSchema(Schema schema) {
        final SchemaBuilder builder = SchemaUtil.copySchemaBasics(schema, SchemaBuilder.struct());
        boolean idFieldExists = false;
        for (Field field: schema.fields()) {
            if (field.name().equals(idFieldName)) {
                idFieldExists = true;
            }
            builder.field(field.name(), field.schema());
        }
        if (!idFieldExists) {
            builder.field(
                    idFieldName,
                    Schema.STRING_SCHEMA);
        }
        return builder.build();
    }

    public ConfigDef config() {
        return CONFIG_DEF;
    }

    public void close() {
        schemaUpdateCache = null;
    }
}
